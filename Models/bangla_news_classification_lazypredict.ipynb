{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installing Lazypredict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pip install lazypredict"]},{"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import lazypredict\n","import ast\n","from gensim.models import Word2Vec\n","from lazypredict.Supervised import LazyClassifier, LazyRegressor\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["file1 = r\"final_newspaper_dataset.csv\" #### The path to the CSV file is needed to be provided here.\n","\n","df = pd.read_csv(file1, on_bad_lines='skip', low_memory=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df.dropna()"]},{"cell_type":"markdown","metadata":{},"source":["## For balancing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Skip this cell only if balanced dataset is not required\n","desired_instances = 10000 ### Number of Instances per Category\n","\n","df =df.groupby('Category').apply(lambda x: x.sample(desired_instances)).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","df['tokenizedContent'] = df['tokenizedContent'].apply(ast.literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_2 = Word2Vec(sentences=df['tokenizedContent'],sg=0, vector_size=100, window=3, min_count=1, workers=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_2.save(\"bangla_word2vec.model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def content_to_vector(content, model):\n","    words = content\n","    word_vectors = [model_2.wv[word] for word in words if word in model.wv]\n","    if len(word_vectors) == 0:\n","        return np.zeros(model.vector_size)\n","    else:\n","        return np.mean(word_vectors, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X =np.array([content_to_vector(content, model_2) for content in df['tokenizedContent']])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y = np.array(df['Category'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(models)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4577551,"sourceId":7814374,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
